{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam1 enabled\n",
      "cam2 enabled\n",
      "cams configued\n"
     ]
    }
   ],
   "source": [
    "ctx = rs.context()\n",
    "devices = ctx.query_devices()\n",
    "var = [i.get_info(rs.camera_info.serial_number) for i in devices]\n",
    "\n",
    "#set up master and slave\n",
    "dev = devices[0].first_depth_sensor()\n",
    "dev.set_option(rs.option.inter_cam_sync_mode,1)\n",
    "dev.get_option(rs.option.inter_cam_sync_mode)\n",
    "\n",
    "dev2 = devices[1].first_depth_sensor()\n",
    "dev2.set_option(rs.option.inter_cam_sync_mode,2)\n",
    "dev2.get_option(rs.option.inter_cam_sync_mode)\n",
    "\n",
    "#start pipeline\n",
    "#cam1: configure depth and color streams\n",
    "pipeline1 = rs.pipeline()\n",
    "config1 = rs.config()\n",
    "config1.enable_device(var[0])\n",
    "config1.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 90)\n",
    "config1.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 60)\n",
    "#config1.enable_record_to_file('master.bag')\n",
    "print('cam1 enabled')\n",
    "\n",
    "#cam2: configure depth and color streams \n",
    "pipeline2 = rs.pipeline()\n",
    "config2 = rs.config()\n",
    "config2.enable_device(var[1])\n",
    "config2.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 90)\n",
    "config2.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 60)\n",
    "#config2.enable_record_to_file('slave.bag')\n",
    "print('cam2 enabled')\n",
    "prof = pipeline1.start(config1)\n",
    "prof2 = pipeline2.start(config2)\n",
    "print('cams configued')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take checkerboard images\n",
    "try:\n",
    "    start = time.time()\n",
    "    mastercount = []\n",
    "    slavecount = []\n",
    "    d = 1\n",
    "    while time.time() - start <100:\n",
    "\n",
    "        #camera 1\n",
    "        frames1 = pipeline1.wait_for_frames()\n",
    "        depthframe1 = frames1.get_depth_frame()\n",
    "        colframe1 = frames1.get_color_frame()\n",
    "        if not depthframe1 or not colframe1:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #convert images to numpy arrays\n",
    "        depthim1 = np.asanyarray(depthframe1.get_data())\n",
    "        colim1 = np.asanyarray(colframe1.get_data())\n",
    "\n",
    "        #apply color map on depth image, convert to 8bit pixel\n",
    "        depthcolmap1 = cv2.applyColorMap(cv2.convertScaleAbs(depthim1, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "        #camera 2\n",
    "        frames2 = pipeline2.wait_for_frames()\n",
    "        depthframe2 = frames2.get_depth_frame()\n",
    "        colframe2 = frames2.get_color_frame()\n",
    "        if not depthframe2 or not colframe2:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #check time sync\n",
    "        #print([depthframe1, depthframe2]) #returns system_time\n",
    "        #counter = depthframe1.get_frame_metadata(rs.frame_metadata_value.frame_counter)\n",
    "        #mastercount.append(counter)\n",
    "        #counter2 = depthframe2.get_frame_metadata(rs.frame_metadata_value.frame_counter)\n",
    "        #slavecount.append(counter2)\n",
    "        #timestamp1 = depthframe1.get_timestamp()\n",
    "        #timestamp2 = depthframe2.get_timestamp()\n",
    "        #print([counter,counter2, timestamp1, timestamp2])\n",
    "        #convert images to numpy arrays\n",
    "        depthim2 = np.asanyarray(depthframe2.get_data())\n",
    "        colim2 = np.asanyarray(colframe2.get_data())\n",
    "\n",
    "        #apply color map on depth image, convert to 8bit pixel\n",
    "        depthcolmap2 = cv2.applyColorMap(cv2.convertScaleAbs(depthim2, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "\n",
    "        #stack all images horizontally\n",
    "        images = np.hstack((colim1, depthcolmap1, colim2, depthcolmap2))\n",
    "\n",
    "        #show images from cameras\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "        #save images and depth map from both cameras by pressing \"s\"\n",
    "        ch = cv2.waitKey(25)\n",
    "        if ch==115:\n",
    "            filename = \"checkerboard/master_%d.jpg\"%d\n",
    "            filename2 = \"checkerboard/slave_%d.jpg\"%d\n",
    "            cv2.imwrite(filename, colim1)\n",
    "            cv2.imwrite(filename2, colim2)\n",
    "            d+=1\n",
    "            #cv2.imwrite(\"depth1.jpg\", depthcolmap1)\n",
    "            #cv2.imwrite(\"depth2.jpg\", depthcolmap2)\n",
    "\n",
    "finally:\n",
    "    #stop streaming\n",
    "    pipeline1.stop()\n",
    "    pipeline2.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    del pipeline1\n",
    "    del config1\n",
    "    del pipeline2\n",
    "    del config2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate extrinsic and intrinsic params from above checkerboards\n",
    "#currently for camera1\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "#prepare object points\n",
    "objp = np.zeros((7*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:9].T.reshape(-1,2)\n",
    "\n",
    "#arrays to store object points and image points from all images\n",
    "objpoints = []\n",
    "masterimgpoints = []\n",
    "\n",
    "path = '/home/alissa/IntelRealSense/checkerboard/'\n",
    "images = glob.glob(path + '/master_*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,9),None)\n",
    "    #if found add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "        masterimgpoints.append(corners2)\n",
    "        #draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (7,9), corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns camera matrix, distortion coefficients, rotation, and translation vectors\n",
    "ret1, mtx1, dist1, rvecs1, tvecs1 = cv2.calibrateCamera(objpoints, masterimgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate extrinsic and intrinsic params from above checkerboards\n",
    "#currently for one camera\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "#prepare object points\n",
    "objp = np.zeros((7*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:9].T.reshape(-1,2)\n",
    "\n",
    "#arrays to store object points and image points from all images\n",
    "objpoints = []\n",
    "slaveimgpoints = []\n",
    "\n",
    "path = '/home/alissa/IntelRealSense/checkerboard/'\n",
    "images = glob.glob(path + '/slave_*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,9),None)\n",
    "    #if found add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "        slaveimgpoints.append(corners2)\n",
    "        #draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (7,9), corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns camera matrix, distortion coefficients, rotation, and translation vectors\n",
    "ret2, mtx2, dist2, rvecs2, tvecs2 = cv2.calibrateCamera(objpoints, slaveimgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 480)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K = camera matrix (mtx)\n",
    "#D = dist (dist)\n",
    "#F = fundamental matrix\n",
    "#E = essential matrix\n",
    "#R = rotation from left to right camera\n",
    "#T = translation from left to right camera\n",
    "ret, M1, d1, M2, d2, R, T, E, F = cv2.stereoCalibrate(\n",
    "    objpoints, masterimgpoints, slaveimgpoints,\n",
    "    mtx1, dist1, mtx2, dist2, gray.shape[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[532.72339941,   0.        , 466.42753055],\n",
       "       [  0.        , 510.36751616, 243.05093151],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intrinsics matrix master [[532.72339941   0.         466.42753055]\n",
      " [  0.         510.36751616 243.05093151]\n",
      " [  0.           0.           1.        ]]\n",
      "dist 1 [[-0.16851522  1.30677432  0.01250941  0.07521741 -4.6680607 ]]\n",
      "intrinsic matrix slave [[491.37667796   0.         249.34152208]\n",
      " [  0.         485.9073681  243.39646834]\n",
      " [  0.           0.           1.        ]]\n",
      "dist 2 [[-1.31199620e-02  4.62466387e-03 -6.94107401e-04 -4.68118632e-02\n",
      "  -2.07436504e+00]]\n",
      "R [[-0.17531009  0.36394608 -0.91477299]\n",
      " [-0.11342419  0.91550939  0.38597604]\n",
      " [ 0.97795773  0.17142288 -0.11921775]]\n",
      "T [[16.61098535]\n",
      " [-9.71021521]\n",
      " [20.73837998]]\n",
      "E [[ -7.1439461  -20.65073472  -6.84688785]\n",
      " [-19.88048886   4.70014911 -16.99058561]\n",
      " [ -3.58638628  18.74150785  -2.47120022]]\n",
      "F [[ 2.26795461e-06  6.84306153e-06 -1.56309530e-03]\n",
      " [ 6.38240418e-06 -1.57502564e-06  3.11693440e-04]\n",
      " [-1.55949150e-03 -4.37454867e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('intrinsics matrix master', M1)\n",
    "print('dist 1', d1)\n",
    "print('intrinsic matrix slave', M2)\n",
    "print('dist 2', d2)\n",
    "print('R',R)\n",
    "print('T',T)\n",
    "print('E',E)\n",
    "print('F',F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.stereoRectify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
